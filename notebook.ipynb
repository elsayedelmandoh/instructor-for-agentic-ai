{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_dFJyvo5q2-"
   },
   "source": [
    "# Lab-1: Building a custom LLM Chatbot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy9Rovk8-cq1"
   },
   "source": [
    "## Groqcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9JF0ir6-flk"
   },
   "source": [
    "- Free Access to AI Models – No payment required to start using AI.\n",
    "\n",
    "- Supports Multiple AI Models – Llama, Llama Vision, Mistral, DeepSeek, and other LLMs for coding, research, and experiments.\n",
    "\n",
    "- Easy-to-Use [Playground](https://console.groq.com/playground) - Interactive tesing environment to test the model and generate code before selection\n",
    "\n",
    "- [API Access](https://console.groq.com/keys?_gl=1*1emrgp3*_ga*MjcxNzk4NzU2LjE3Mzg2OTgyNDM.*_ga_4TD0X2GEZG*MTczODY5ODI0My4xLjEuMTczODY5ODI1Ny4wLjAuMA..) with Free Quota – The API has [rate limits](https://console.groq.com/docs/rate-limits), but it's sufficient for student projects and non-commercial use.\n",
    "\n",
    "- No Expensive Hardware Needed – [Run AI models](https://groq.com/groqcloud) fast in the cloud without needing a high-end GPU or workstation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7j4yi6jK-fho"
   },
   "source": [
    "### Guiding Model Behavior and Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system_instruction: Defines the role and style of the model\n",
    "\n",
    "- Example:   \n",
    "• system_instruction=\"Act as a concise academic tutor. You will\n",
    "provide real-world example and analogies to make the topics\n",
    "engaging and understandable by the undergrad students “\n",
    "\n",
    "- Effect:   \n",
    "• Directs the model to deliver concise, academic-style\n",
    "responses. Force the model to respond with analogy and\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WWE-fgU-fdk"
   },
   "source": [
    "### Preventing Harmful Outputs and fostering responsible AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Useful for healthcare assistance, sensitive content\n",
    "generation (e.g., to avoid demographic bias)\n",
    "\n",
    "safety_settings= {\n",
    "HarmCategory.HARM_CATEGORY_HATE_SPEECH:\n",
    "HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "HarmCategory.HARM_CATEGORY_HARASSMENT:\n",
    "HarmBlockThreshold.BLOCK_LOW_AND_ABOVE, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to develop an LLM Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get an API key   \n",
    "2. Create an LLM client   \n",
    "3. Select a pre-trained LLM   \n",
    "4. Define the setting parameters   \n",
    "5. Generate static response to add functionality   \n",
    "6. Generate stream response for chatbot   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get an API key\n",
    "\n",
    "Visit: [groq keys](https://console.groq.com/keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an LLM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Select a pre-trained LLM\n",
    "\n",
    "test before you select: [link](https://console.groq.com/playground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in Agentic AI\\n\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"gimme step by step end to end project tp build group of agents, persona for each agent using langchain and langgraph\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"<think>\\nOkay, let me try to figure out how to approach this project. The user wants to build a group of agents using LangChain and LangGraph, each with their own personas. Hmm, first, I need to understand what exactly LangChain and LangGraph offer. LangChain is a framework for building applications with large language models, right? And LangGraph is part of that ecosystem for creating stateful, graph-based agent workflows.\\n\\nSo the user is looking for an end-to-end project. Let me break it down step by step. They mentioned personas for each agent. That means each agent should have a specific role or character. Maybe like a team of specialists working together. For example, a planner, a researcher, a summarizer, etc. Each agent would handle a part of the task.\\n\\nFirst, I need to outline the project structure. Let's start with the problem they want to solve. Maybe a customer service scenario where different agents handle different aspects of a query. Or perhaps a collaborative research project where agents gather information, analyze it, and present findings. The user didn't specify, so I'll choose a common use case like a customer support system with multiple agents.\\n\\nNext, setting up the environment. They'll need Python, LangChain, LangGraph, a language model like OpenAI's GPT, and maybe a vector store for memory. Oh, and dependencies like Pydantic for data models.\\n\\nThen, defining the agents. Each agent should have a unique persona. For example, a Customer Support Agent, a Technical Support Agent, a Billing Agent, and a Manager. Each with their own tools and responsibilities. The Customer Support Agent handles initial queries, Technical Support deals with technical issues, Billing with payment issues, and the Manager oversees the workflow.\\n\\nCreating the agents involves using LangChain's AgentExecutor and the specific tools each agent uses. The Technical Support Agent might use a database to look up technical issues, the Billing Agent could access payment systems, etc. The Manager agent would coordinate between them.\\n\\nDesigning the workflow with LangGraph is next. The graph should define the flow between agents. For instance, a customer query starts with the Customer Support Agent, who routes it to the appropriate specialist. The graph needs nodes for each agent and edges defining the transitions. Conditions can determine which agent to route to next based on the query type.\\n\\nTesting the workflow is crucial. The user needs to simulate different customer queries and see how the agents interact. They should check if the routing works, if each agent performs its task correctly, and if the final response is accurate.\\n\\nDeployment and monitoring come last. The system should be deployed, maybe using a web framework like FastAPI, and monitored for performance and errors. Logging and feedback mechanisms can help improve the agents over time.\\n\\nWait, but how exactly do the agents communicate? Each agent's output is passed to the next in the workflow. The LangGraph graph handles the state and routing. The user might need to define the state schema, which includes the current step, user input, agent responses, etc.\\n\\nAlso, personas should be clearly defined. Each agent's prompt should reflect their role. For example, the Technical Support Agent's prompt might start with \\\"You are a technical support expert. Your task is to resolve technical issues...\\\" to guide their responses.\\n\\nI should make sure to mention how to integrate tools. For instance, the Billing Agent might have access to a payment API, and the Technical Agent to a knowledge base. Using LangChain's tools and agents, each agent can be configured with the right set of tools.\\n\\nWhat about memory? If the agents need to remember past interactions, a memory component like Redis or a database could be used. But maybe the user wants to keep it simple for now, using in-memory state through LangGraph.\\n\\nTesting with different scenarios will help identify if the routing logic is correct. For example, if a query is about a technical problem, does it go to the Technical Support Agent? What if it's a billing question? The conditions in the graph should handle that.\\n\\nI should also think about error handling. If an agent can't resolve an issue, maybe the Manager steps in or escalates the problem. The workflow should have a way to handle such cases gracefully.\\n\\nDocumentation is important too. The user should document each agent's role, the workflow, and any dependencies. This helps in maintaining and expanding the system later.\\n\\nIn summary, the steps are: set up the environment, define agent personas with their tools, create the agents using LangChain, design the workflow with LangGraph, test the system, and deploy it with monitoring. Each part needs careful consideration to ensure the agents work together effectively.\\n</think>\\n\\nHere's a step-by-step guide to building a multi-agent system with personas using **LangChain** and **LangGraph**. This example creates a collaborative research team where agents work together to answer complex questions.\\n\\n---\\n\\n### **Step 1: Define the Project Scope**\\n**Goal**: Build a team of agents that collaborate to answer complex questions by dividing tasks into:\\n- **Researcher**: Finds relevant information from web sources\\n- **Analyst**: Analyzes and synthesizes data\\n- **Writer**: Creates a final summary\\n- **Manager**: Coordinates the workflow\\n\\n---\\n\\n### **Step 2: Set Up the Environment**\\nInstall required packages:\\n```bash\\npip install langchain langgraph langgraph-checkpoint langchain-community langchain-openai\\n```\\n\\n---\\n\\n### **Step 3: Define Agent Personas**\\nEach agent has a unique role and tools:\\n1. **Researcher Agent**  \\n   - **Persona**: \\\"You are a researcher who finds accurate information from web sources.\\\"\\n   - **Tools**: `WebSearchAPI`, `WikipediaAPI`\\n   - **Responsibility**: Search for relevant data.\\n\\n2. **Analyst Agent**  \\n   - **Persona**: \\\"You are an analyst who identifies patterns and synthesizes complex data.\\\"\\n   - **Tools**: `DataAnalysisTool` (custom for processing structured data)\\n   - **Responsibility**: Process and analyze the researcher's findings.\\n\\n3. **Writer Agent**  \\n   - **Persona**: \\\"You are a writer who creates clear, concise summaries from analysis.\\\"\\n   - **Tools**: `MarkdownFormatter` (for formatting output)\\n   - **Responsibility**: Generate the final response.\\n\\n4. **Manager Agent**  \\n   - **Persona**: \\\"You are a project manager who coordinates tasks between agents.\\\"\\n   - **Tools**: `WorkflowManager` (for routing tasks)\\n   - **Responsibility**: Orchestrate the workflow.\\n\\n---\\n\\n### **Step 4: Create Agents with LangChain**\\nDefine agents using `AgentExecutor` and custom tools:\\n```python\\nfrom langchain.agents import AgentExecutor, create_tool_calling_agent\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_community.tools import WikipediaAPIWrapper\\n\\n# Initialize LLM\\nllm = ChatOpenAI(model=\\\"gpt-4\\\")\\n\\n# Researcher Agent\\nweb_search = WebSearchAPIWrapper()\\nwikipedia = WikipediaAPIWrapper()\\nresearcher_agent = create_tool_calling_agent(llm, [web_search, wikipedia], \\\"Researcher\\\")\\n\\n# Analyst Agent\\nclass DataAnalysisTool:\\n    def run(self, data):\\n        # Simulate data analysis\\n        return f\\\"Analysis: {data} processed.\\\"\\nanalyst_agent = create_tool_calling_agent(llm, [DataAnalysisTool()], \\\"Analyst\\\")\\n\\n# Writer Agent\\nclass MarkdownFormatter:\\n    def run(self, text):\\n        return f\\\"### Summary\\\\n{text}\\\"\\nwriter_agent = create_tool_calling_agent(llm, [MarkdownFormatter()], \\\"Writer\\\")\\n\\n# Manager Agent (uses LangGraph for workflow)\\nfrom langgraph.graph import StateGraph, END\\nfrom langgraph.checkpoint.memory import MemorySaver\\n\\nclass AgentState(TypedDict):\\n    input: str\\n    research: str\\n    analysis: str\\n    output: str\\n\\ndef researcher_node(state: AgentState):\\n    result = researcher_agent.run(state[\\\"input\\\"])\\n    return {\\\"research\\\": result}\\n\\ndef analyst_node(state: AgentState):\\n    result = analyst_agent.run(state[\\\"research\\\"])\\n    return {\\\"analysis\\\": result}\\n\\ndef writer_node(state: AgentState):\\n    result = writer_agent.run(state[\\\"analysis\\\"])\\n    return {\\\"output\\\": result}\\n\\n# Build the graph\\nworkflow = StateGraph(AgentState)\\nworkflow.add_node(\\\"research\\\", researcher_node)\\nworkflow.add_node(\\\"analyze\\\", analyst_node)\\nworkflow.add_node(\\\"write\\\", writer_node)\\n\\nworkflow.set_entry_point(\\\"research\\\")\\nworkflow.add_edge(\\\"research\\\", \\\"analyze\\\")\\nworkflow.add_edge(\\\"analyze\\\", \\\"write\\\")\\nworkflow.add_edge(\\\"write\\\", END)\\n\\nmanager_agent = workflow.compile(checkpointer=MemorySaver())\\n```\\n\\n---\\n\\n### **Step 5: Run the Workflow**\\nExecute the workflow for a query:\\n```python\\n# Example query\\nquery = \\\"What are the economic impacts of renewable energy adoption?\\\"\\n\\n# Run the agent graph\\nresult = manager_agent.invoke({\\\"input\\\": query})\\nprint(result[\\\"output\\\"])\\n```\\n\\n---\\n\\n### **Step 6: Test and Iterate**\\n- **Test Cases**:  \\n  1. \\\"How does climate change affect agriculture?\\\"  \\n  2. \\\"Compare the efficiency of solar vs wind energy.\\\"  \\n- **Debugging**: Use `print(result)` to inspect intermediate outputs.\\n\\n---\\n\\n### **Step 7: Deploy and Monitor**\\n- **Deployment**: Wrap the workflow in a FastAPI endpoint for external access.\\n- **Monitoring**: Add logging and metrics tracking for agent performance.\\n\\n---\\n\\n### **Key Features**\\n- **Modularity**: Each agent is independent and can be updated separately.\\n- **Scalability**: Add more agents (e.g., a \\\"Validator\\\" to fact-check results).\\n- **Customization**: Replace tools with domain-specific APIs (e.g., financial data for economic analysis).\\n\\n---\\n\\n### **Example Output**\\nFor the query \\\"What are the economic impacts of renewable energy adoption?\\\", the system might return:\\n```\\n### Summary\\nRenewable energy adoption reduces long-term energy costs and creates jobs in green sectors. However, initial infrastructure investments can be high. Analysis shows a net economic benefit within 5-10 years in most regions.\\n```\\n\\n---\\n\\nThis framework provides a flexible foundation for building complex agent systems. You can expand it by adding more agents, integrating additional tools, or refining personas for specific use cases.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=0.6,\n",
    "    max_completion_tokens=4096,\n",
    "    top_p=0.95,\n",
    "    reasoning_effort=\"default\",\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define the setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert in Agentic AI. Provide structured and insightful responses to queries \n",
    "about building and refining agentic AI systems\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate static response to add functionality   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"What is agentic AI?\" Let me start by recalling what I know about agentic AI. I remember that it's a type of AI that can act autonomously, right? So, it's different from traditional AI systems that just follow specific instructions. Agentic AI has more autonomy, maybe like having goals and decision-making abilities.\n",
      "\n",
      "I need to define agentic AI clearly. Maybe start with the basic idea that it's a self-directed AI system. Then break down the key characteristics. Autonomy is important—how much control does the AI have? It should be able to make decisions without constant human input. Then there's goal-directed behavior. It should have objectives and work towards them, maybe even adjusting its strategies as needed.\n",
      "\n",
      "Another aspect is learning and adaptation. Traditional AI might be trained on static data, but agentic AI can learn from its environment and adapt. This makes it more flexible in dynamic situations. Planning and reasoning are also key. It needs to think through problems, maybe use tools or resources, and handle complex tasks.\n",
      "\n",
      "Self-awareness or reflection might be part of it too. Can the AI monitor its own actions and improve over time? That's a more advanced feature. I should mention examples of where agentic AI is used, like in robotics, personalized assistants, or autonomous vehicles. These examples help illustrate the concept.\n",
      "\n",
      "I should also consider the challenges. Developing such systems is complex. Issues like ensuring safety, ethical use, transparency, and accountability come up. There's the risk of unintended behaviors if the AI isn't properly constrained. Plus, integrating agentic AI into existing systems can be tricky.\n",
      "\n",
      "Looking at the future, maybe discuss current research directions. Combining agentic AI with machine learning, like reinforcement learning, could be a point. Also, how it's being applied in different industries. But I need to make sure the explanation is clear without too much jargon.\n",
      "\n",
      "Wait, the user might not be familiar with all the technical terms. I should explain terms like autonomy, goal-directed behavior in simple language. Maybe use analogies, like comparing agentic AI to a self-driving car that not only follows traffic rules but also plans the best route dynamically.\n",
      "\n",
      "Also, the user might be interested in why agentic AI matters. It's about creating more flexible and efficient systems that can handle tasks requiring initiative and adaptability. This could lead to advancements in various fields, but also raises important ethical questions that need addressing.\n",
      "\n",
      "I should structure the answer by first defining agentic AI, then listing its key characteristics, provide examples, mention challenges, and touch on future directions. Keep it organized so the user can follow along step by step. Avoid being too technical but ensure the core concepts are covered. Check if there's any confusion between agentic AI and other AI types, like reactive or model-based AI, but maybe that's beyond the scope here.\n",
      "\n",
      "Make sure to highlight the difference between agentic AI and traditional AI systems. Traditional AI is more about following programmed instructions, while agentic AI has the ability to learn, adapt, and make decisions on its own. Emphasize the autonomy and goal-oriented nature as the main differentiators.\n",
      "\n",
      "Also, when discussing challenges, it's important to mention the ethical implications and the need for robust frameworks to manage these systems. Maybe include something about how researchers are working on making these systems safe and reliable.\n",
      "\n",
      "In summary, the answer should cover definition, characteristics, examples, challenges, and future prospects. Keep it concise but comprehensive, using clear examples and avoiding unnecessary complexity.\n",
      "</think>\n",
      "\n",
      "**Agentic AI** refers to artificial intelligence systems that exhibit **autonomy, self-direction, and goal-oriented behavior**, enabling them to act independently in dynamic environments. Unlike traditional AI systems that follow fixed rules or respond to specific inputs, agentic AI systems can **set goals, plan, adapt to new information, and make decisions** with minimal human intervention. These systems are inspired by human agency and aim to replicate qualities like intentionality, learning, and problem-solving.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Characteristics of Agentic AI**\n",
      "1. **Autonomy**  \n",
      "   - Operates independently, making decisions without constant human oversight.  \n",
      "   - Can manage tasks in unstructured or changing environments (e.g., navigating a city or troubleshooting a system).  \n",
      "\n",
      "2. **Goal-Directed Behavior**  \n",
      "   - Pursues specific objectives, such as optimizing a workflow or solving a complex problem.  \n",
      "   - Adjusts strategies dynamically when obstacles arise (e.g., rerouting during traffic delays).  \n",
      "\n",
      "3. **Learning and Adaptation**  \n",
      "   - Continuously learns from interactions, data, or feedback to improve performance.  \n",
      "   - Adapts to new scenarios, leveraging techniques like reinforcement learning or meta-learning.  \n",
      "\n",
      "4. **Planning and Reasoning**  \n",
      "   - Breaks down complex tasks into subtasks and sequences actions efficiently.  \n",
      "   - Uses logical reasoning, heuristics, or tools (e.g., APIs, databases) to achieve goals.  \n",
      "\n",
      "5. **Self-Awareness and Reflection**  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_static_response(user_message):\n",
    "    \"\"\"Generate a single static response\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen/qwen3-32b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(get_static_response(\"What is agentic ai?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generate stream response for chatbot   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking about the differences between agentic AI and traditional AI. Let me start by recalling what I know about both concepts. Traditional AI, as I understand it, refers to systems that are rule-based or use machine learning models to perform specific tasks. They're typically designed for narrow purposes, like playing chess or recognizing images, and don't have a sense of autonomy or long-term goals.\n",
      "\n",
      "Now, agentic AI is a newer term I've been hearing more about. From what I've read, agentic AI systems are supposed to be more autonomous. They can set their own goals, plan, and adapt over time. They might use multiple models in a coordinated way, like combining a language model with a planning model. This makes them more flexible and capable of handling complex tasks that require reasoning and decision-making.\n",
      "\n",
      "I should break down the differences into clear categories. Maybe start with autonomy: traditional AI follows pre-set rules, while agentic AI can adjust its own actions. Then, goal orientation—traditional AI is task-specific, agentic AI has longer-term goals. Adaptability: traditional AI is static, agentic AI learns and evolves. Complexity of tasks—traditional AI handles simple tasks, agentic AI handles complex, multi-step ones. Architecture: traditional AI uses single models, agentic AI uses multiple models working together. Human interaction—traditional AI is passive, agentic AI is proactive. Examples might help too, like comparing a chess program to a virtual assistant that can plan a trip.\n",
      "\n",
      "Wait, I need to make sure I'm not mixing up any details. Let me double-check some points. Autonomy in agentic AI includes self-directed behavior without constant human input. Traditional AI requires explicit programming. Also, agentic AI can handle uncertainty better, maybe using reinforcement learning or similar techniques. Traditional AI might not have that. Oh, and agentic AI can have memory and learn from past interactions, which is part of their adaptability.\n",
      "\n",
      "I should also mention the implications of these differences. Agentic AI could lead to more versatile applications but might raise ethical concerns about autonomy and control. Traditional AI is more predictable and easier to regulate. The user might want to know when to use each type. Applications for agentic AI could include personalized assistants, dynamic environments, or research. Traditional AI is still better for straightforward, well-defined tasks.\n",
      "\n",
      "Hmm, maybe the user is considering developing an AI system and wants to choose between the two. So explaining the trade-offs would be helpful. Also, mentioning that agentic AI is an emerging field with ongoing research could be important, as it's not as mature as traditional AI yet. They might need to weigh the benefits of autonomy against the current limitations in reliability and control.\n",
      "\n",
      "I should structure the answer clearly, perhaps with bullet points or sections for each difference. Starting with definitions, then moving into each key area of distinction. Examples will make it concrete. Concluding with use cases and implications will give the user a practical understanding. Let me make sure the language is clear and avoids jargon where possible, since the user might not be familiar with all the technical terms.\n",
      "</think>\n",
      "\n",
      "Agentic AI and traditional AI differ fundamentally in **autonomy**, **goal orientation**, **flexibility**, and **complexity of tasks they can handle**. Here's a structured breakdown of their key distinctions:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Autonomy and Goal Setting**\n",
      "- **Traditional AI**:  \n",
      "  - Operates within **predefined rules or static training data**.  \n",
      "  - Executes **specific, narrow tasks** (e.g., image classification, language translation) with no capacity for self-directed behavior.  \n",
      "  - Requires explicit programming for every task it performs.  \n",
      "\n",
      "- **Agentic AI**:  \n",
      "  - Demonstrates **self-directed autonomy**: Can set goals, adapt plans, and act independently based on context.  \n",
      "  - Uses **dynamic reasoning** to pursue long-term objectives (e.g., planning a trip, solving a complex problem).  \n",
      "  - Learns from interactions and adjusts strategies over time (e.g., using reinforcement learning).  \n",
      "\n",
      "**Example**:  \n",
      "- Traditional AI: A chess engine that follows hardcoded strategies.  \n",
      "- Agentic AI: A virtual assistant that researches solutions to a user’s problem without being told *how* to approach it.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Adaptability and Learning**\n",
      "- **Traditional AI**:  \n",
      "  - Static models trained on fixed datasets.  \n",
      "  - Limited to tasks it was explicitly trained for (e.g., spam detection in emails).  \n",
      "  - No ability to improve or generalize beyond its training scope.  \n",
      "\n",
      "- **Agentic AI**:  \n",
      "  - Continuously learns from new data and user interactions (e.g., updating knowledge databases).  \n",
      "  - Combines **multiple AI models** (e.g., a language model with a reasoning model) to adapt to new scenarios.  \n",
      "  - Uses **memory and reflection** to refine decision-making over time.  \n",
      "\n",
      "---\n",
      "\n",
      "### **3. Complexity of Tasks**\n",
      "- **Traditional AI**:  \n",
      "  - Excels at **single-step, deterministic\n",
      "<think>\n",
      "Okay, the user is asking about the differences between agentic AI and traditional AI. Let me start by recalling what I know about both concepts. Traditional AI, as I understand it, refers to systems that are rule-based or use machine learning models to perform specific tasks. They're typically designed for narrow purposes, like playing chess or recognizing images, and don't have a sense of autonomy or long-term goals.\n",
      "\n",
      "Now, agentic AI is a newer term I've been hearing more about. From what I've read, agentic AI systems are supposed to be more autonomous. They can set their own goals, plan, and adapt over time. They might use multiple models in a coordinated way, like combining a language model with a planning model. This makes them more flexible and capable of handling complex tasks that require reasoning and decision-making.\n",
      "\n",
      "I should break down the differences into clear categories. Maybe start with autonomy: traditional AI follows pre-set rules, while agentic AI can adjust its own actions. Then, goal orientation—traditional AI is task-specific, agentic AI has longer-term goals. Adaptability: traditional AI is static, agentic AI learns and evolves. Complexity of tasks—traditional AI handles simple tasks, agentic AI handles complex, multi-step ones. Architecture: traditional AI uses single models, agentic AI uses multiple models working together. Human interaction—traditional AI is passive, agentic AI is proactive. Examples might help too, like comparing a chess program to a virtual assistant that can plan a trip.\n",
      "\n",
      "Wait, I need to make sure I'm not mixing up any details. Let me double-check some points. Autonomy in agentic AI includes self-directed behavior without constant human input. Traditional AI requires explicit programming. Also, agentic AI can handle uncertainty better, maybe using reinforcement learning or similar techniques. Traditional AI might not have that. Oh, and agentic AI can have memory and learn from past interactions, which is part of their adaptability.\n",
      "\n",
      "I should also mention the implications of these differences. Agentic AI could lead to more versatile applications but might raise ethical concerns about autonomy and control. Traditional AI is more predictable and easier to regulate. The user might want to know when to use each type. Applications for agentic AI could include personalized assistants, dynamic environments, or research. Traditional AI is still better for straightforward, well-defined tasks.\n",
      "\n",
      "Hmm, maybe the user is considering developing an AI system and wants to choose between the two. So explaining the trade-offs would be helpful. Also, mentioning that agentic AI is an emerging field with ongoing research could be important, as it's not as mature as traditional AI yet. They might need to weigh the benefits of autonomy against the current limitations in reliability and control.\n",
      "\n",
      "I should structure the answer clearly, perhaps with bullet points or sections for each difference. Starting with definitions, then moving into each key area of distinction. Examples will make it concrete. Concluding with use cases and implications will give the user a practical understanding. Let me make sure the language is clear and avoids jargon where possible, since the user might not be familiar with all the technical terms.\n",
      "</think>\n",
      "\n",
      "Agentic AI and traditional AI differ fundamentally in **autonomy**, **goal orientation**, **flexibility**, and **complexity of tasks they can handle**. Here's a structured breakdown of their key distinctions:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Autonomy and Goal Setting**\n",
      "- **Traditional AI**:  \n",
      "  - Operates within **predefined rules or static training data**.  \n",
      "  - Executes **specific, narrow tasks** (e.g., image classification, language translation) with no capacity for self-directed behavior.  \n",
      "  - Requires explicit programming for every task it performs.  \n",
      "\n",
      "- **Agentic AI**:  \n",
      "  - Demonstrates **self-directed autonomy**: Can set goals, adapt plans, and act independently based on context.  \n",
      "  - Uses **dynamic reasoning** to pursue long-term objectives (e.g., planning a trip, solving a complex problem).  \n",
      "  - Learns from interactions and adjusts strategies over time (e.g., using reinforcement learning).  \n",
      "\n",
      "**Example**:  \n",
      "- Traditional AI: A chess engine that follows hardcoded strategies.  \n",
      "- Agentic AI: A virtual assistant that researches solutions to a user’s problem without being told *how* to approach it.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Adaptability and Learning**\n",
      "- **Traditional AI**:  \n",
      "  - Static models trained on fixed datasets.  \n",
      "  - Limited to tasks it was explicitly trained for (e.g., spam detection in emails).  \n",
      "  - No ability to improve or generalize beyond its training scope.  \n",
      "\n",
      "- **Agentic AI**:  \n",
      "  - Continuously learns from new data and user interactions (e.g., updating knowledge databases).  \n",
      "  - Combines **multiple AI models** (e.g., a language model with a reasoning model) to adapt to new scenarios.  \n",
      "  - Uses **memory and reflection** to refine decision-making over time.  \n",
      "\n",
      "---\n",
      "\n",
      "### **3. Complexity of Tasks**\n",
      "- **Traditional AI**:  \n",
      "  - Excels at **single-step, deterministic\n"
     ]
    }
   ],
   "source": [
    "def get_stream_response(user_message):\n",
    "    \"\"\"Generate a streaming response for real-time chatbot interaction\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen/qwen3-32b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    for chunk in completion:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            full_response += chunk.choices[0].delta.content\n",
    "    print()\n",
    "    return full_response\n",
    "\n",
    "\n",
    "print(get_stream_response(\"what's different between agentic AI and traditional AI?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build UI using Gradio install gradio by run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llmgroq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
